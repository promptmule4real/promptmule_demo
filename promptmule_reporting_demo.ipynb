{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNzj/h5+QcD/NeU1twqRkJC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/promptmule4real/promptmule_demo/blob/main/promptmule_reporting_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PromptMule API Demo Suite\n",
        "\n",
        "Welcome to the **PromptMule API Demo Suite**! This hands-on tool is designed to streamline your experience with the PromptMule API, allowing you to delve into various features, from generating dynamic prompts to assessing semantic response scores, and observing your token usage efficiency through our advanced caching mechanisms.\n",
        "\n",
        "## What Does This Code Offer?\n",
        "\n",
        "This interactive script serves as your gateway to the PromptMule API, simplifying access to AI models through optimized API requests. With this suite, you gain the ability to:\n",
        "\n",
        "1. Securely authenticate and retrieve a token for seamless API interactions.\n",
        "2. Easily generate or obtain your unique API key.\n",
        "3. Dynamically create and dispatch a series of prompts to the API, experimenting with various semantic similarities and response limits.\n",
        "4. Monitor detailed logs of each API interaction (available in verbose mode) for in-depth analysis.\n",
        "5. Compile comprehensive reports showcasing prompt responses, token utilization, and cache-enabled savings.\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "- **Running the Script**: Ensure you're in a compatible Python environment before initiating the script.\n",
        "- **User Credentials**: Input your username, password, and application name when prompted to authenticate your session.\n",
        "- **Verbose Mode Selection**: Opt for verbose mode (\"yes\") to access detailed API communication logs or choose \"no\" for a more streamlined, less cluttered output.\n",
        "- **Cost-Saving Strategy Input**: Define your cost-saving strategy theme, forming the basis for the generated test prompts.\n",
        "- **Report Analysis**: Upon completion of the prompt cycles, the script presents you with:\n",
        "   - An exhaustive breakdown of prompt responses.\n",
        "   - A concise summary of your API usage statistics.\n",
        "   - Insightful data reflecting the cost-efficiency achieved via caching.\n",
        "- **Profile Management**: As a final step, you have the option to delete your user profile. Exercise caution, as this process is irreversible.\n",
        "\n",
        "## Need More Information?\n",
        "\n",
        "Dive deeper into the intricate workings of the PromptMule API, explore our extensive [documentation](https://promptmule.com/docs), or reach out for support on the [PromptMule website](https://promptmule.com).\n",
        "\n",
        "Embark on your journey to efficient AI interactions. Happy testing!\n",
        "\n",
        "## Demo Notebook\n",
        "\n",
        "Access the interactive demonstration Jupyter Notebook through this link: [PromptMule API Demo Notebook](https://github.com/promptmule4real/promptmule_demo/blob/main/promptmule_reporting_demo.ipynb).\n",
        "\n",
        "## License\n",
        "\n",
        "This project is licensed under the MIT License - see the [LICENSE.md](https://github.com/promptmule4real/report_demo/blob/ce9f220dd37427538a564fddbdcb6ef122b1ea2f/LICENSE) file for details.\n"
      ],
      "metadata": {
        "id": "5ngI3FzjrRom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMnLKlvAqu94"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Promptmule Semantic Cache Reporting Guide\n",
        "Date: October 12, 2023\n",
        "Purpose: To provide guidance and best practices for application developers looking to save money\n",
        "during the development and production phases of building generative AI-based applications with OpenAI.\n",
        "\n",
        "Author: the friendly folks at Promptmule\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import random\n",
        "\n",
        "# The Endpoints: Constants for API interactions\n",
        "ENDPOINT = 'https://api.promptmule.com/'\n",
        "LOGIN = 'login'\n",
        "KEY_GEN = 'api-keys'\n",
        "PROMPT = 'prompt'\n",
        "LIST_API_KEYS = 'api-keys/'\n",
        "DELETE = 'profile/'\n",
        "\n",
        "# User-specific details\n",
        "# These are what you'll use to define your login and app for Promptmule to know it's you\n",
        "USERNAME = \"YOUR_USER_NAME\"\n",
        "PASSWORD = \"YOUR_PASSWORD\"\n",
        "APPNAME = \"YOUR_APPNAME\"\n",
        "\n",
        "# simple prompt template to give some test prompts for this demo\n",
        "# example: USERS_MESSAGE = \"Please provide a cost-saving strategy for implementing AI applications while we establish the API account: \"\n",
        "#\n",
        "USERS_MESSAGE = \"Please provide a cost-saving strategy for implementing AI applications while we establish the API account: \"\n",
        "\n",
        "# Headers for API interactions\n",
        "headers = {'Content-Type': 'application/json'}\n",
        "\n",
        "# --- FUNCTIONS ---\n",
        "\n",
        "def login_to_promptmule():\n",
        "    \"\"\"\n",
        "    Log into PromptMule service and retrieve authentication token.\n",
        "    \"\"\"\n",
        "    data = {\"username\": USERNAME, \"password\": PASSWORD}\n",
        "    response = requests.post(ENDPOINT + LOGIN, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"token\"]\n",
        "    else:\n",
        "        print(f\"Login failed: {response.status_code}\")\n",
        "        print(json.dumps(response.json(), indent=4))\n",
        "        exit()\n",
        "\n",
        "def generate_or_fetch_api_key():\n",
        "    \"\"\"\n",
        "    Attempt to generate a new API key for the user's app or fetch an existing one.\n",
        "    \"\"\"\n",
        "    data = {\"app-name\": APPNAME}\n",
        "    response = requests.post(ENDPOINT + KEY_GEN, headers=headers, json=data)\n",
        "\n",
        "    if response.status_code == 200 and \"api-key\" in response.json():\n",
        "        return response.json()[\"api-key\"]\n",
        "    else:\n",
        "        # If generating a new one fails, try to fetch an existing API key\n",
        "        response = requests.get(ENDPOINT + LIST_API_KEYS, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            for key_data in response.json().get(\"api-keys\", []):\n",
        "                if key_data.get(\"app-name\") == APPNAME:\n",
        "                    return key_data.get(\"api-key\")\n",
        "    print(\"Error fetching or generating API keys.\")\n",
        "    exit()\n",
        "\n",
        "def generate_prompt(users_message, variation):\n",
        "    \"\"\"\n",
        "    Formulate a prompt message given a user's message and a variation number.\n",
        "    \"\"\"\n",
        "    base_prompt = \"You are a developer aiming to save money using OpenAI. Share an implementation tip related to the strategy: \"\n",
        "    return f\"{base_prompt}{users_message}. Variation: {variation}\"\n",
        "\n",
        "def track_semantic_scores(response_json):\n",
        "    \"\"\"\n",
        "    Extract semantic scores and associated data from the API's response.\n",
        "    \"\"\"\n",
        "    return [(choice['prompt-id'], choice.get('score'), choice['message']['content'], choice['index']) for choice in response_json['choices']]\n",
        "\n",
        "def send_prompt_requests(users_message, semantic_similarity, max_response_quantity):\n",
        "    \"\"\"\n",
        "    Send a series of prompt requests to the API based on the specified parameters.\n",
        "    \"\"\"\n",
        "    for variation in range(1, int(prompt_variations * 0.9) + 1):  # Use 90% of the available variations\n",
        "        api_call_body = {\n",
        "            \"model\": \"gpt-3.5-turbo\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": generate_prompt(users_message, variation)}],\n",
        "            \"max_tokens\": \"50\",\n",
        "            \"temperature\": \"0.99\",\n",
        "            \"user\": USERNAME,\n",
        "            \"api\": \"openai\", # this is specific to Promptmule, and selects the LLM you'd like to prompt\n",
        "            \"semantic\": str(semantic_similarity), # this determines the percentage prompt similarity that is acceptable to return from the cache for this call\n",
        "            \"sem_num\": str(max_response_quantity) # this determines the max number of prompt/response pairs to return if they are greater than \"semantic\" percentage match\n",
        "        }\n",
        "\n",
        "        response = requests.post(ENDPOINT + PROMPT, headers={'x-api-key': api_key, 'Content-Type': 'application/json'}, json=api_call_body)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            print(\"\\nPrompt response:\")\n",
        "            print(json.dumps(response.json(), indent=4))\n",
        "\n",
        "            choices_data = track_semantic_scores(response.json())\n",
        "            for choice in choices_data:\n",
        "                df.loc[len(df)] = [choice[0], semantic_similarity, choice[1], choice[2], choice[3]]\n",
        "\n",
        "            print(\"\\nTop Implementation Tip:\", choices_data[0][2])\n",
        "            print(\"\\nOther Tips:\", *[choice[2] for choice in choices_data[1:]], sep=\"\\n\")\n",
        "        else:\n",
        "            print(f\"\\nError with prompt variation {variation}. Status code: {response.status_code}\")\n",
        "            print(json.dumps(response.json(), indent=4))\n",
        "\n",
        "def fetch_data(endpoint, headers, success_message, fail_message):\n",
        "    \"\"\"Make a GET request and print the results.\"\"\"\n",
        "    response = requests.get(endpoint, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        print(f\"\\n{success_message}:\")\n",
        "        print(json.dumps(response.json(), indent=4))\n",
        "    else:\n",
        "        print(f\"\\n{fail_message} {response.status_code}:\")\n",
        "        print(json.dumps(response.json(), indent=4))\n",
        "\n",
        "def delete_data(endpoint, headers):\n",
        "    \"\"\"Make a DELETE request and print the results.\"\"\"\n",
        "    response = requests.delete(endpoint, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        print(\"\\nOperation successful!\")\n",
        "    else:\n",
        "        print(f\"\\nOperation failed with status code {response.status_code}:\")\n",
        "        print(json.dumps(response.json(), indent=4))\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "\n",
        "# 1. Log in to the service and update headers with the obtained token\n",
        "token = login_to_promptmule()\n",
        "headers[\"Authorization\"] = f\"Bearer {token}\"\n",
        "print(\"Login successful! Token acquired.\")\n",
        "\n",
        "# 2. Generate or retrieve the user's API key\n",
        "api_key = generate_or_fetch_api_key()\n",
        "print(f\"API Key: {api_key}\")\n",
        "\n",
        "# 3. Gather user input for prompt testing\n",
        "users_message = input(USERS_MESSAGE)\n",
        "\n",
        "# 4. Define constants for prompt variations and requests\n",
        "prompt_variations = 25\n",
        "requests_per_variation = 5\n",
        "df = pd.DataFrame(columns=['Prompt ID', 'Semantic Similarity', 'Score', 'Choice Content', 'Choice Index'])\n",
        "\n",
        "# 5. Send prompt requests with varying semantic similarities and max response counts\n",
        "semantic_nums = [1.0, 0.75, 0.5]\n",
        "max_responses = list(range(1, 11))  # From 1 to 10\n",
        "for sem_num in semantic_nums:\n",
        "    send_prompt_requests(users_message, sem_num, random.choice(max_responses))\n",
        "\n",
        "# 6. Display the results in a structured report\n",
        "print(\"\\nReport:\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "# 7. Fetch and display user data summary\n",
        "fetch_data(ENDPOINT + LIST_API_KEYS, headers, \"List of API keys\", \"Failed to list API keys\")\n",
        "fetch_data(ENDPOINT + 'usage', {\"Authorization\": f\"Bearer {token}\", \"x-api-key\": api_key}, \"Usage Summary\", \"Failed to fetch usage summary\")\n",
        "fetch_data(ENDPOINT + 'usage/daily-stats', {\"Authorization\": f\"Bearer {token}\", \"x-api-key\": api_key}, \"Daily Usage Stats\", \"Failed to fetch daily usage stats\")\n",
        "\n",
        "print(\"\\nReport Summary:\")\n",
        "print(f\"Username: {USERNAME}\")\n",
        "print(f\"API Key: {api_key}\")\n",
        "print(f\"Number of Cost-saving Strategy Variations Sent: {prompt_variations}\")\n",
        "print(f\"Number of Requests per Strategy Variation: {requests_per_variation}\")\n",
        "\n",
        "# 8. Optionally allow user to delete their profile\n",
        "#if input(\"\\nDo you really want to delete your user profile? (yes/no): \").lower() == 'yes':\n",
        "#    delete_data(ENDPOINT + DELETE, headers)\n"
      ]
    }
  ]
}