{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP1YLkDnRtLlJ7OeJKnoWV8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/promptmule4real/promptmule_demo/blob/main/PromptMule_demo_v1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "olgnZBplUkFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PromptMule API Demo Suite v1.1\n",
        "\n",
        "# Welcome to the **PromptMule API Demo Suite**! This hands-on tool is designed to streamline your experience with the PromptMule API, allowing you to delve into various features, from generating dynamic prompts to assessing semantic response scores, and observing your token usage efficiency through our advanced caching mechanisms.\n",
        "\n",
        "## What Does This Code Offer?\n",
        "\n",
        "# This interactive script serves as your gateway to the PromptMule API, simplifying access to AI models through optimized API requests. With this suite, you gain the ability to:\n",
        "\n",
        "# 1. Dynamically create and dispatch a series of prompts to the API, experimenting with various semantic similarities and response limits.\n",
        "# 2. Monitor detailed logs of each API interaction (available in verbose mode) for in-depth analysis.\n",
        "# 3. Compile comprehensive reports showcasing prompt responses, token utilization, and cache-enabled savings.\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "# - **Running the Script**: Ensure you're in a compatible Python environment before initiating the script.\n",
        "# - **API Key**: Enter your unique API key obtained from the PromptMule website (https://promptmule.com).\n",
        "# - **Verbose Mode Selection**: Opt for verbose mode (\"yes\") to access detailed API communication logs or choose \"no\" for a more streamlined, less cluttered output.\n",
        "# - **Cost-Saving Strategy Input**: Define your cost-saving strategy theme, forming the basis for the generated test prompts.\n",
        "\n",
        "## Need More Information?\n",
        "\n",
        "# Dive deeper into the intricate workings of the PromptMule API, explore our extensive [documentation](https://promptmule.com/docs), check out the [support discord](https://discord.gg/Ceun9EQ8) or reach out for support on the [PromptMule website](https://promptmule.com).\n",
        "\n",
        "# Embark on your journey to efficient AI interactions. Happy testing!\n",
        "\n",
        "# Demo Notebook\n",
        "\n",
        "# Access the interactive demonstration Jupyter Notebook through this link: [PromptMule API Demo Notebook](https://github.com/promptmule4real/promptmule_demo/blob/main/promptmule_reporting_demo.ipynb).\n",
        "\n",
        "# License\n",
        "\n",
        "# This project is licensed under the MIT License - see the [LICENSE.md](https://github.com/promptmule4real/report_demo/blob/ce9f220dd37427538a564fddbdcb6ef122b1ea2f/LICENSE) file for details.\n"
      ],
      "metadata": {
        "id": "VezD6s2YXukB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import requests\n",
        "import json\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Constants\n",
        "BASE_URL = 'https://api.promptmule.com/'\n",
        "\n",
        "# Constants for API interactions\n",
        "ENDPOINT = 'https://api.promptmule.com/'\n",
        "#LOGIN = 'login'\n",
        "#KEY_GEN = 'api-keys'\n",
        "PROMPT = 'prompt'\n",
        "LIST_API_KEYS = 'api-keys/'\n",
        "DELETE = 'profile/'\n",
        "USAGE = 'usage'\n",
        "DAILY_STATS = 'usage/daily-stats'\n",
        "\n",
        "# Set display options for better readability\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n",
        "pd.set_option('display.max_colwidth', None)  # Show full width of the column content\n",
        "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping of the dataframe\n"
      ],
      "metadata": {
        "id": "4qyn_nntIIrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import DEBUG\n",
        "\n",
        "#api_key = \" \"\n",
        "#print(\"Input your PromptMule API Key:\")\n",
        "#api_key = input()\n",
        "\n",
        "# DEBUG\n",
        "DEBUG = False\n",
        "\n",
        "api_key = \"6VDD3H6B4Y8Aftlnm7n069JvRIkaucmOIj1YyE69\" # demo key\n",
        "users_message = \"improving user experience\"\n",
        "users_message = \"improving profitability\"\n",
        "users_message = \"reducing costs of OpenAI usage\"\n",
        "\n",
        "print(f\"Your API key is: {api_key}\")"
      ],
      "metadata": {
        "id": "OlWNhpsjH3_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to formulate a prompt message given a user's message and a variation number\n",
        "def generate_prompt(users_message, variation):\n",
        "    base_prompt = \"You are a developer aiming to save money using OpenAI. Share only one implementation tip for using a cache-as-a-service wiht your code: \"\n",
        "    return f\"{base_prompt}{users_message}. Variation: {variation}\"\n",
        "\n",
        "# Function to extract semantic scores and associated data from the API's response\n",
        "def track_semantic_scores(response_json):\n",
        "    return [(choice['prompt-id'], choice.get('score'), choice['message']['content'], choice['index']) for choice in response_json['choices']]\n",
        "\n",
        "# Function to send a series of prompt requests to the API based on specified parameters\n",
        "def send_prompt_requests(api_key, users_message, semantic_similarity, max_response_quantity, variations, df):\n",
        "    headers = {\"Content-Type\": \"application/json\", \"x-api-key\": api_key}\n",
        "    prompt_variations = variations\n",
        "\n",
        "    for variation in range(1, int(prompt_variations * 0.9) + 1):  # Use 90% of the available variations\n",
        "        api_call_body = {\n",
        "            \"model\": \"gpt-3.5-turbo\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": generate_prompt(users_message, variation)}],\n",
        "            \"max_tokens\": \"50\",\n",
        "            \"temperature\": \"0.2\",\n",
        "            \"user\": \"demouser\",\n",
        "            \"api\": \"openai\", # This is specific to Promptmule and selects the LLM you'd like to prompt\n",
        "            \"semantic\": str(semantic_similarity), # This determines the percentage prompt similarity that is acceptable to return from the cache for this call\n",
        "            \"sem_num\": str(max_response_quantity) # This determines the max number of prompt/response pairs to return if they are greater than \"semantic\" percentage match\n",
        "        }\n",
        "\n",
        "        if DEBUG:\n",
        "          print(\"api call body:\", api_call_body)\n",
        "          print(json.dumps(api_call_body, indent=4))\n",
        "          print(\"\\nSending prompt request:\",json.dumps(api_call_body, indent=4))\n",
        "\n",
        "        response = requests.post(ENDPOINT + PROMPT, headers=headers, json=api_call_body)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            if DEBUG:\n",
        "              print(\"\\nPrompt response:\")\n",
        "              print(json.dumps(response.json(), indent=4))\n",
        "            else:\n",
        "              print(\".\")\n",
        "\n",
        "            choices_data = track_semantic_scores(response.json())\n",
        "            for choice in choices_data:\n",
        "                df.loc[len(df)] = [choice[0], semantic_similarity, choice[1], choice[2], choice[3]]\n",
        "                if DEBUG:\n",
        "                  print(\"\\nTop Implementation Tip:\", choices_data[0][2])\n",
        "                  print(\"\\nOther Tips:\", *[choice[2] for choice in choices_data[1:]], sep=\"\\n\")\n",
        "        else:\n",
        "          print(f\"\\nError with prompt variation {variation}. Status code: {response.status_code}\")\n",
        "          print(json.dumps(response.json(), indent=4))\n",
        "\n",
        "# Function to fetch data from an API endpoint and print the results\n",
        "def fetch_data(headers, endpoint, success_message, fail_message):\n",
        "    #headers = {\"Content-Type\": \"application/json\", \"x-api-key\": api_key}\n",
        "    response = requests.get(endpoint, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        print(f\"\\n{success_message}:\")\n",
        "        print(json.dumps(response.json(), indent=4))\n",
        "    else:\n",
        "        print(f\"\\n{fail_message} {response.status_code}:\")\n",
        "        print(json.dumps(response.json(), indent=4))"
      ],
      "metadata": {
        "id": "taCslmcgMadu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MAIN EXECUTION ---\n",
        "\n",
        "# 1. Gather user input for prompt testing\n",
        "#def get_cost_strategy():\n",
        "#    print(\"Please enter the most important development aspect for your app:\")\n",
        "#    users_message = input()\n",
        "#\n",
        "#    if not users_message:\n",
        "#        print(\"A cost-saving strategy theme is required. Please try again.\")\n",
        "#        return get_cost_strategy()\n",
        "#\n",
        "#    return users_message\n",
        "\n",
        "#users_message = get_cost_strategy()\n",
        "\n",
        "# 2. Define constants for prompt variations and requests, and a dataframe for reporting\n",
        "prompt_variations = 3\n",
        "requests_per_variation = 3\n",
        "df = pd.DataFrame(columns=['Prompt ID', 'Similarity Target', 'Similarity Score', 'Response', 'Response Index'])\n",
        "data_frame_output = df\n",
        "\n",
        "# 3. Send prompt requests with varying semantic similarities and max response counts\n",
        "semantic_nums = [1.0, 0.75, 0.5]\n",
        "max_responses = list(range(1, 11))  # From 1 to 10\n",
        "variations = 3\n",
        "i = 0\n",
        "for sem_num in semantic_nums:\n",
        "    i += 1\n",
        "    send_prompt_requests(api_key, users_message, sem_num, random.choice(max_responses), variations, df)"
      ],
      "metadata": {
        "id": "Q8HZZsSzXlkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Display the results in a structured report\n",
        "print(\"\\nPrompt-ing Report:\")\n",
        "print(\"Prompt:\", )\n",
        "print(df.to_string(index=True))"
      ],
      "metadata": {
        "id": "KqK9q3-QUnhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#username = input()\n",
        "#pw = input()\n",
        "\n",
        "username = \"demo\"\n",
        "pw = \"Abcd@1234!\"\n",
        "\n",
        "# Function to log in to the service and retrieve authentication token\n",
        "def login_to_promptmule(api_key, username, pw):\n",
        "    headers = {\"Content-Type\": \"application/json\", \"x-api-key\": api_key}\n",
        "    api_call_body = {\n",
        "        \"username\": username,\n",
        "        \"password\": pw\n",
        "    }\n",
        "    response = requests.post(ENDPOINT + LOGIN, headers=headers, json=api_call_body)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"token\"]\n",
        "    else:\n",
        "        print(f\"Login failed: {response.status_code}\")\n",
        "        print(json.dumps(response.json(), indent=4))\n",
        "        print(\"Try Again.\")\n",
        "        return \"\"\n",
        "\n",
        "token = login_to_promptmule(api_key, username, pw)\n",
        "headers = {\"Content-Type\": \"application/json\", \"x-api-key\": api_key, \"Authorization\": f\"Bearer {token}\"}#\n",
        "\n",
        "fetch_data(headers, ENDPOINT + LIST_API_KEYS, \"List of API keys\", \"Failed to list API keys\")"
      ],
      "metadata": {
        "id": "0gbIrDRkeoRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_data(headers, ENDPOINT + USAGE, \"Usage Summary\", \"Failed to fetch usage summary\")"
      ],
      "metadata": {
        "id": "OwWaBtuGgnKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_data(headers, ENDPOINT + DAILY_STATS, \"Daily Usage Stats\", \"Failed to fetch daily usage stats\")\n"
      ],
      "metadata": {
        "id": "ELM5DVAOguQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nReport Summary:\")\n",
        "print(f\"API Key: {headers['x-api-key'].split(' ')[-1]}\")\n",
        "print(f\"Number of Cost-saving Strategy Variations Sent: {prompt_variations}\")\n",
        "print(f\"Number of Requests per Strategy Variation: {requests_per_variation}\")"
      ],
      "metadata": {
        "id": "9uwdmRQHUS3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}